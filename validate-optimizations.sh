#!/bin/bash

# Quick validation script to check if latency optimizations are working

echo "ğŸ” Validating AI Latency Optimizations..."
echo ""

# Check if files exist
echo "1. Checking modified files..."
FILES=(
    "backend/services/ollama_service.py"
    "backend/services/whisper_service.py"
    "backend/services/performance.py"
    "backend/routes/ask.py"
    "frontend/src/services/api.js"
    "optimize-network.sh"
    "test_performance.py"
)

for file in "${FILES[@]}"; do
    if [ -f "$file" ]; then
        echo "  âœ“ $file"
    else
        echo "  âœ— $file NOT FOUND"
    fi
done

# Check for connection pooling code
echo ""
echo "2. Checking for connection pooling implementation..."
if grep -q "requests.Session" backend/services/ollama_service.py; then
    echo "  âœ“ Connection pooling found in ollama_service.py"
else
    echo "  âœ— Connection pooling NOT found in ollama_service.py"
fi

if grep -q "HTTPAdapter" backend/services/ollama_service.py; then
    echo "  âœ“ HTTPAdapter configuration found"
else
    echo "  âœ— HTTPAdapter NOT found"
fi

# Check for reduced context
echo ""
echo "3. Checking for optimized context settings..."
if grep -q '"num_ctx": 1024' backend/services/ollama_service.py; then
    echo "  âœ“ Reduced context window (1024)"
else
    echo "  âš   Context window might not be optimized"
fi

if grep -q '"num_predict": 200' backend/services/ollama_service.py; then
    echo "  âœ“ Reduced prediction limit (200)"
else
    echo "  âš   Prediction limit might not be optimized"
fi

# Check for timing instrumentation
echo ""
echo "4. Checking for performance monitoring..."
if grep -q "time.time()" backend/services/ollama_service.py; then
    echo "  âœ“ Timing instrumentation found"
else
    echo "  âœ— Timing instrumentation NOT found"
fi

if grep -q "timing" backend/services/ollama_service.py; then
    echo "  âœ“ Timing data returned in response"
else
    echo "  âš   Timing data might not be included"
fi

# Check frontend timeout
echo ""
echo "5. Checking frontend timeout..."
if grep -q "timeout: 45000" frontend/src/services/api.js; then
    echo "  âœ“ Frontend timeout optimized (45s)"
else
    echo "  âš   Frontend timeout might not be optimized"
fi

# Check Python dependencies
echo ""
echo "6. Checking Python dependencies..."
python3 -c "import requests" 2>/dev/null && echo "  âœ“ requests module available" || echo "  âœ— requests module NOT available"
python3 -c "from urllib3.util.retry import Retry" 2>/dev/null && echo "  âœ“ urllib3 module available" || echo "  âœ— urllib3 module NOT available"

# Summary
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Validation complete!"
echo ""
echo "Next steps:"
echo "  1. Run: ./optimize-network.sh (optional, requires sudo)"
echo "  2. Restart backend: cd backend && uvicorn main:app --reload"
echo "  3. Test: python3 test_performance.py"
echo ""
echo "Expected improvement: 5-10x faster AI requests! ğŸš€"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
